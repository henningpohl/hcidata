@inproceedings{Larsen2019,
author = {Larsen, Joachim Normann and Jacobsen, Tórur Højgaard and Boring, Sebastian and Bergström, Joanna and Pohl, Henning},
title = {The Influence of Hand Size on Touch Accuracy},
year = {2019},
isbn = {9781450368254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3338286.3340115},
abstract = {Touch accuracy is not just dependent on the performance of the touch sensor itself. Instead, aspects like phone grip or occlusion of the screen have been shown to also have an influence on accuracy. Yet, these are all dependent on one underlying factor: the size and proportions of the user's hand. To better understand touch input, we investigate how 11 hand features influence accuracy. We find that thumb length in particular correlates significantly with touch accuracy and accounts for about 12% of touch error variance. Furthermore, we show that measures of some higher level interactions also correlate with hand size.},
booktitle = {Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services},
articleno = {4},
numpages = {11},
keywords = {mobile interaction, Touch input, pointing},
location = {Taipei, Taiwan},
series = {MobileHCI '19}
}

@inproceedings{Lilija2019,
author = {Lilija, Klemen and Pohl, Henning and Boring, Sebastian and Hornb\ae{}k, Kasper},
title = {Augmented Reality Views for Occluded Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3290605.3300676},
abstract = {We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {augmented reality, manipulation task, finger-camera},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{Pohl2013,
author = {Pohl, Henning and Murray-Smith, Roderick},
title = {Focused and Casual Interactions: Allowing Users to Vary Their Level of Engagement},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2470654.2481307},
abstract = {We describe the focused-casual continuum, a framework for describing interaction techniques according to the degree to which they allow users to adapt how much attention and effort they choose to invest in an interaction conditioned on their current situation. Casual interactions are particularly appropriate in scenarios where full engagement with devices is frowned upon socially, is unsafe, physically challenging or too mentally taxing. Novel sensing approaches which go beyond direct touch enable wider use of casual interactions, which will often be 'around device' interactions. We consider the degree to which previous commercial products and research prototypes can be considered as fitting the focused-casual framework, and describe the properties using control theoretic concepts. In an experimental study we observe that users naturally apply more precise and more highly engaged interaction techniques when faced with a more challenging task and use more relaxed gestures in easier tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2223–2232},
numpages = {10},
keywords = {foreground/background, casual interaction, peripheral interaction, deliberate interaction, sensing, interaction techniques},
location = {Paris, France},
series = {CHI '13}
}

@article{Bergstroem2022,
author = {Bergström, Joanna and Knibbe, Jarrod and Pohl, Henning and Hornbæk, Kasper},
title = {Sense of Agency and User Experience: Is There a Link?},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1073-0516},
doi = {10.1145/3490493},
abstract = {Sense of control is increasingly used as a measure of quality in human-computer interaction. Control has been investigated mainly at a high level, using subjective questionnaire data, but also at a low level, using objective data on participants’ sense of agency. However, it remains unclear how differences in higher level, experienced control reflect lower level sense of control. We study that link in two experiments. In the first one we measure the low-level sense of agency with button, touchpad, and on-skin input. The results show a higher sense of agency with on-skin input. In the second experiment, participants played a simple game controlled with the same three inputs. We find that on-skin input results in both increased sense and experience of control compared to touchpad input. However, the corresponding difference is not found between on-skin and button input, whereas the button performed better in the experiment task. These results suggest that other factors of user experience spill over to the experienced control at rates that overcome differences in the sense of control. We discuss the implications for using subjective measures about the sense of control in evaluating qualities of interaction.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {mar},
articleno = {28},
numpages = {22},
keywords = {agency, User experience, on-skin input}
}

@inproceedings{Dalsgaard2021,
author = {Dalsgaard, Tor-Salve and Knibbe, Jarrod and Bergström, Joanna},
title = {Modeling Pointing for 3D Target Selection in VR},
year = {2021},
isbn = {9781450390927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3489849.3489853},
abstract = { Virtual reality (VR) allows users to interact similarly to how they do in the physical world, such as touching, moving, and pointing at objects. To select objects at a distance, most VR techniques rely on casting a ray through one or two points located on the user’s body (e.g., on the head and a finger), and placing a cursor on that ray. However, previous studies show that such rays do not help users achieve optimal pointing accuracy nor correspond to how they would naturally point. We seek to find features, which would best describe natural pointing at distant targets. We collect motion data from seven locations on the hand, arm, and body, while participants point at 27 targets across a virtual room. We evaluate the features of pointing and analyse sets of those for predicting pointing targets. Our analysis shows an 87% classification accuracy between the 27 targets for the best feature set and a mean distance of 23.56&nbsp;cm in predicting pointing targets across the room. The feature sets can inform the design of more natural and effective VR pointing techniques for distant object selection.},
booktitle = {Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology},
articleno = {42},
numpages = {10},
keywords = {target selection, pointing, Virtual reality},
location = {Osaka, Japan},
series = {VRST '21}
}

@article{Pohl2022,
author = {Pohl, Henning and Mottelson, Aske},
title = {Hafnia Hands: A Multi-Skin Hand Texture Resource for Virtual Reality Research},
journal = {Frontiers in Virtual Reality},
volume = {3},
year = {2022},
doi = {10.3389/frvir.2022.719506},
issn = {2673-4192}
}